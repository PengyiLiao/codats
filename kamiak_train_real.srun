#!/bin/bash
#SBATCH --job-name=train_real
#SBATCH --output=slurm_logs/train_%A_%a.out
#SBATCH --error=slurm_logs/train_%A_%a.err
#SBATCH --cpus-per-task=3
#SBATCH --gres=gpu:1
#SBATCH --partition=cook,free_gpu,cahnrs_gpu,kamiak
#SBATCH --time=1-00:00:00
#SBATCH --mem=20G
#SBATCH --array=0-539

# My computer
#gpumem=4500
# SBATCH --partition=cook
# SBATCH --cpus-per-task=4
# SBATCH --gres=gpu:0
# SBATCH --mem=10G
# Kamiak
gpumem=0
# SBATCH --partition=cook,free_gpu,cahnrs_gpu,kamiak
# SBATCH --cpus-per-task=3
# SBATCH --gres=gpu:1
# SBATCH --mem=20G

. kamiak_config.sh

# Errors
handle_terminate() { echo "Exiting"; exit 1; }
handle_error() { echo "Error occured -- exiting"; exit 1; }
trap "handle_terminate" SIGTERM SIGINT

# Get suffix, i.e. files stored in kamiak-{models,logs}-suffix
suffix=$1; shift
[[ -z $suffix ]] && { echo "no suffix specified"; handle_error; }

# Adapt in both directions, then do upper bound
model=fcn
methods=("vrada" "rdann" "cycada" "random" "dann" "deepjdot" "dann_grl" "none" "upper")  # slowest to fastest for shortest time
debugnums=(1 2 3)
#sources=("utdata_wrist"  "utdata_pocket")
#targets=("utdata_pocket" "utdata_wrist")
sources=("ucihar_1" "ucihar_2" "ucihar_3" "ucihar_4" "ucihar_5" "ucihar_6" "ucihar_7" "ucihar_8" "ucihar_9" "ucihar_10" "ucihar_11" "ucihar_12" "uwave_1" "uwave_2" "uwave_3" "uwave_4" "uwave_5" "uwave_6" "uwave_7" "uwave_8")
targets=("ucihar_2" "ucihar_1" "ucihar_4" "ucihar_3" "ucihar_6" "ucihar_5" "ucihar_8" "ucihar_7" "ucihar_10" "ucihar_9" "ucihar_12" "ucihar_11" "uwave_2" "uwave_1" "uwave_4" "uwave_3" "uwave_6" "uwave_5" "uwave_8" "uwave_7")

# Make sure we're using the right number
correct_min=0
correct_max=$(( ${#methods[@]} * ${#debugnums[@]} * ${#sources[@]} - 1))
[[ ${#sources[@]} == ${#targets[@]} ]] || \
    { echo "source/target sizes should match"; handle_error; }
[[ $SLURM_ARRAY_TASK_MIN == $correct_min ]] || \
    { echo "array min should be $correct_min"; handle_error; }
[[ $SLURM_ARRAY_TASK_MAX == $correct_max ]] || \
    { echo "array max should be $correct_max"; handle_error; }

# Indexing: https://stackoverflow.com/a/34363187
index=$SLURM_ARRAY_TASK_ID
index1max=${#sources[@]}
index2max=${#debugnums[@]}
index3=$((index / (index1max * index2max)))
index=$((index - index3 * index1max * index2max))
index2=$((index / index1max))
index1=$((index % index1max))

method="${methods[$index3]}"
debugnum="${debugnums[$index2]}"
source="${sources[$index1]}"
target="${targets[$index1]}"

# Upper bound is actually "none" but without a target domain and with other args
additional_args=()
if [[ $method == "upper" ]]; then
    method="none"
    source="$target"
    target=""
    additional_args+=("--best_source" "--notrain_on_source_valid")
fi

# Training / model options
steps=15000
lr=0.0001
model=fcn

if [[ $method == "vrada" || $method == "rdann" ]]; then
    model="$method"
    batch=64
elif [[ $method == "random" ]]; then
    batch=50
    additional_args+=("--log_val_steps=100")
else
    batch=250
fi

# Pretraining - VRADA requires its custom reconstruction loss
if [[ $method == "vrada" || $method == "random" ]]; then
    pretraining=0
else
    pretraining=1000
fi

echo "$suffix #$SLURM_ARRAY_TASK_ID"
echo "Method: $method"
echo "DebugNum: $debugnum"
echo "Other args: $@"
echo "$source --> $target"

cd "$remotedir"
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
module load cuda/10.0.130 cudnn/7.5.1.10_cuda10.0 python3/3.6.5
python3 main.py \
    --logdir="$logFolder-$suffix" --modeldir="$modelFolder-$suffix" \
    --model="$model" --steps="$steps" --train_batch=$batch --pretrain_steps=$pretraining --lr="$lr" \
    --method="$method" --source="$source" --target="$target" --debugnum="$debugnum" \
    --gpumem="$gpumem" "${additional_args[@]}" "$@" || handle_error
