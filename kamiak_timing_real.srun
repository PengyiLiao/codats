#!/bin/bash
#SBATCH --job-name=timing_real
#SBATCH --output=slurm_logs/timing_%A_%a.out
#SBATCH --error=slurm_logs/timing_%A_%a.err
#SBATCH --cpus-per-task=3
#SBATCH --gres=gpu:1
#SBATCH --partition=cook,free_gpu,cahnrs_gpu,kamiak
#SBATCH --time=0-01:00:00
#SBATCH --mem=20G
#SBATCH --array=0-80

# My computer
#gpumem=4500
# SBATCH --partition=cook
# SBATCH --cpus-per-task=4
# SBATCH --gres=gpu:0
# SBATCH --mem=10G
# Kamiak
gpumem=0
# SBATCH --partition=cook,free_gpu,cahnrs_gpu,kamiak
# SBATCH --cpus-per-task=3
# SBATCH --gres=gpu:1
# SBATCH --mem=20G

. kamiak_config.sh

# Errors
handle_terminate() { echo "Exiting"; exit 1; }
handle_error() { echo "Error occured -- exiting"; exit 1; }
trap "handle_terminate" SIGTERM SIGINT

# Get suffix, i.e. files stored in kamiak-{models,logs}-suffix
suffix=$1; shift
[[ -z $suffix ]] && { echo "no suffix specified"; handle_error; }

# Adapt in both directions, then do upper bound
model=fcn
methods=("vrada" "rdann" "cycada" "random" "dann" "deepjdot" "dann_grl" "none" "upper")  # slowest to fastest for shortest time
debugnums=(1 2 3)
sources=("ucihar_1" "uwave_1" "utdata_wrist")
targets=("ucihar_2" "uwave_2" "utdata_pocket")

# Make sure we're using the right number
correct_min=0
correct_max=$(( ${#methods[@]} * ${#debugnums[@]} * ${#sources[@]} - 1))
[[ ${#sources[@]} == ${#targets[@]} ]] || \
    { echo "source/target sizes should match"; handle_error; }
[[ $SLURM_ARRAY_TASK_MIN == $correct_min ]] || \
    { echo "array min should be $correct_min"; handle_error; }
[[ $SLURM_ARRAY_TASK_MAX == $correct_max ]] || \
    { echo "array max should be $correct_max"; handle_error; }

# Indexing: https://stackoverflow.com/a/34363187
index=$SLURM_ARRAY_TASK_ID
index1max=${#sources[@]}
index2max=${#debugnums[@]}
index3=$((index / (index1max * index2max)))
index=$((index - index3 * index1max * index2max))
index2=$((index / index1max))
index1=$((index % index1max))

method="${methods[$index3]}"
debugnum="${debugnums[$index2]}"
source="${sources[$index1]}"
target="${targets[$index1]}"

# Print in an easily-parsable format, before changing method name below
echo "$suffix,$method,$source,$target,$debugnum,$SLURM_ARRAY_TASK_ID"

# Upper bound is actually "none" but without a target domain and with other args
additional_args=()
if [[ $method == "upper" ]]; then
    method="none"
    source="$target"
    target=""
    additional_args+=("--best_source" "--notrain_on_source_valid")
fi

# Do the timing
additional_args+=("--time_training")

# Training / model options
steps=22  # we'll skip the first couple since it has to compile it the first one
lr=0.0001
model=fcn
batch=64
pretraining=0

if [[ $method == "vrada" || $method == "rdann" ]]; then
    model="$method"
fi

cd "$remotedir"
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
module load cuda/10.0.130 cudnn/7.5.1.10_cuda10.0 python3/3.6.5
python3 main.py \
    --logdir="$logFolder-$suffix" --modeldir="$modelFolder-$suffix" \
    --model="$model" --steps="$steps" --train_batch=$batch --pretrain_steps=$pretraining --lr="$lr" \
    --method="$method" --source="$source" --target="$target" --debugnum="$debugnum" \
    --gpumem="$gpumem" "${additional_args[@]}" "$@" || handle_error
